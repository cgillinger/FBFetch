# fetch_facebook_comments.py
# Version 1.0 - Kommentarr√§knare f√∂r Facebook-sidor
#
# Detta skript r√§knar kommentarer och replies p√• Facebook-sidors inl√§gg
# och genererar CSV-rapporter per m√•nad.

import csv
import json
import os
import time
import requests
import logging
import argparse
import sys
from datetime import datetime, timedelta
from calendar import monthrange
from config import (
    ACCESS_TOKEN, TOKEN_LAST_UPDATED, INITIAL_START_YEAR_MONTH,
    API_VERSION, CACHE_FILE,
    BATCH_SIZE, MAX_RETRIES, RETRY_DELAY,
    TOKEN_VALID_DAYS
)

# Konfigurera loggning
def setup_logging():
    """Konfigurera loggning med datumst√§mplad loggfil"""
    now = datetime.now()
    log_dir = "logs"
    
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    log_filename = os.path.join(log_dir, f"facebook_comments_{now.strftime('%Y-%m-%d_%H-%M-%S')}.log")
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename),
            logging.FileHandler("facebook_comments.log"),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"Startar loggning till fil: {log_filename}")
    
    return logger

logger = setup_logging()

# API-anropsr√§knare
api_call_count = 0
start_time = time.time()
rate_limit_backoff = 1.0
consecutive_successes = 0

def check_token_expiry():
    """Kontrollera om token snart g√•r ut och varna anv√§ndaren"""
    try:
        last_updated = datetime.strptime(TOKEN_LAST_UPDATED, "%Y-%m-%d")
        days_since = (datetime.now() - last_updated).days
        days_left = TOKEN_VALID_DAYS - days_since
        
        logger.info(f"üîë Token skapades f√∂r {days_since} dagar sedan ({days_left} dagar kvar till utg√•ng).")
        
        if days_left <= 7:
            logger.warning(f"‚ö†Ô∏è VARNING: Din token g√•r ut inom {days_left} dagar! Skapa en ny token snart.")
        elif days_left <= 0:
            logger.error(f"‚ùå KRITISKT: Din token har g√•tt ut! Skapa en ny token omedelbart.")
            return False
        
        return True
    except Exception as e:
        logger.error(f"‚ùå Kunde inte validera token-utg√•ngsdatum: {e}")
        return False

def api_request(url, params, retry_count=0):
    """G√∂r ett API-anrop med felhantering och rate limiting"""
    global api_call_count, start_time, rate_limit_backoff, consecutive_successes
    
    api_call_count += 1
    
    # Dynamisk rate limiting
    if api_call_count % 50 == 0:
        elapsed = time.time() - start_time
        rate = api_call_count / elapsed * 3600
        logger.info(f"üìä API-hastighet: {rate:.0f} anrop/timme ({api_call_count} anrop p√• {elapsed/60:.1f} min)")
    
    try:
        time.sleep(0.1 * rate_limit_backoff)
        response = requests.get(url, params=params, timeout=30)
        
        if response.status_code == 200:
            consecutive_successes += 1
            if consecutive_successes > 10 and rate_limit_backoff > 1.0:
                rate_limit_backoff = max(1.0, rate_limit_backoff * 0.9)
            return response.json()
        
        elif response.status_code == 429 or response.status_code == 17:
            consecutive_successes = 0
            rate_limit_backoff = min(5.0, rate_limit_backoff * 1.5)
            logger.warning(f"‚ö†Ô∏è Rate limit tr√§ffad. V√§ntar {RETRY_DELAY * rate_limit_backoff:.1f}s...")
            time.sleep(RETRY_DELAY * rate_limit_backoff)
            
            if retry_count < MAX_RETRIES:
                return api_request(url, params, retry_count + 1)
            else:
                logger.error(f"‚ùå Max retry-f√∂rs√∂k n√•dda f√∂r {url}")
                return None
        
        else:
            logger.error(f"‚ùå HTTP {response.status_code}: {response.text}")
            return None
            
    except requests.exceptions.Timeout:
        logger.warning(f"‚ö†Ô∏è Timeout f√∂r {url}")
        if retry_count < MAX_RETRIES:
            time.sleep(RETRY_DELAY)
            return api_request(url, params, retry_count + 1)
        return None
        
    except Exception as e:
        logger.error(f"‚ùå API-fel: {e}")
        return None

def load_cache():
    """Ladda sidnamn fr√•n cache"""
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Kunde inte ladda cache: {e}")
    return {}

def save_cache(cache):
    """Spara sidnamn till cache"""
    try:
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"‚ùå Kunde inte spara cache: {e}")

def get_all_pages():
    """H√§mta alla Facebook-sidor som token har √•tkomst till"""
    logger.info("üìã H√§mtar lista √∂ver Facebook-sidor...")
    
    url = f"https://graph.facebook.com/{API_VERSION}/me/accounts"
    params = {"access_token": ACCESS_TOKEN, "limit": 100}
    
    data = api_request(url, params)
    
    if not data or "data" not in data:
        logger.error("‚ùå Kunde inte h√§mta sidor. Kontrollera din token och beh√∂righeter.")
        return []
    
    pages = data["data"]
    page_ids = [(page["id"], page["name"]) for page in pages]
    logger.info(f"‚úÖ Hittade {len(page_ids)} sidor")
    
    return page_ids

def filter_placeholder_pages(page_list):
    """Filtrera bort placeholder-sidor (Srholder*)"""
    filtered_pages = []
    filtered_out = []
    
    for page_id, page_name in page_list:
        if page_name and page_name.startswith('Srholder') and page_name[8:].isdigit():
            filtered_out.append((page_id, page_name))
        else:
            filtered_pages.append((page_id, page_name))
    
    if filtered_out:
        placeholder_names = [name for _, name in filtered_out]
        logger.info(f"üö´ Filtrerade bort {len(filtered_out)} placeholder-sidor: {', '.join(placeholder_names)}")
    
    logger.info(f"‚úÖ {len(filtered_pages)} sidor kvar efter filtrering")
    return filtered_pages

def get_page_access_token(page_id):
    """Konvertera systemanv√§ndartoken till Page Access Token"""
    url = f"https://graph.facebook.com/{API_VERSION}/{page_id}"
    params = {
        "fields": "access_token",
        "access_token": ACCESS_TOKEN
    }
    
    data = api_request(url, params)
    
    if not data or "error" in data or "access_token" not in data:
        error_msg = data.get("error", {}).get("message", "Ok√§nt fel") if data and "error" in data else "Kunde inte h√§mta token"
        logger.warning(f"‚ö†Ô∏è Kunde inte h√§mta Page Access Token f√∂r sida {page_id}: {error_msg}")
        return None
    
    return data["access_token"]

def get_posts_for_month(page_id, page_token, year, month):
    """H√§mta alla posts f√∂r en sida under en specifik m√•nad"""
    days_in_month = monthrange(year, month)[1]
    since_date = datetime(year, month, 1)
    until_date = datetime(year, month, days_in_month, 23, 59, 59)
    
    since_timestamp = int(since_date.timestamp())
    until_timestamp = int(until_date.timestamp())
    
    url = f"https://graph.facebook.com/{API_VERSION}/{page_id}/posts"
    params = {
        "access_token": page_token,
        "since": since_timestamp,
        "until": until_timestamp,
        "limit": 100,
        "fields": "id,created_time"
    }
    
    all_posts = []
    
    while True:
        data = api_request(url, params)
        
        if not data or "data" not in data:
            break
        
        posts = data["data"]
        all_posts.extend(posts)
        
        # Kolla pagination
        if "paging" in data and "next" in data["paging"]:
            url = data["paging"]["next"]
            params = {}  # URL inneh√•ller redan alla params
        else:
            break
    
    return all_posts

def count_comments_on_post(post_id, page_token):
    """R√§kna kommentarer och replies p√• ett specifikt inl√§gg"""
    url = f"https://graph.facebook.com/{API_VERSION}/{post_id}/comments"
    params = {
        "access_token": page_token,
        "summary": "true",
        "filter": "stream",
        "limit": 100
    }
    
    total_comments = 0
    total_replies = 0
    
    while True:
        data = api_request(url, params)
        
        if not data:
            break
        
        if "data" in data:
            comments = data["data"]
            total_comments += len(comments)
            
            # R√§kna replies p√• varje kommentar
            for comment in comments:
                comment_id = comment.get("id")
                if comment_id:
                    reply_count = count_replies_on_comment(comment_id, page_token)
                    total_replies += reply_count
        
        # Summary ger total count om tillg√§ngligt
        if "summary" in data and "total_count" in data["summary"]:
            # Anv√§nd summary f√∂r snabbare r√§kning
            total_comments = data["summary"]["total_count"]
            break
        
        # Pagination
        if "paging" in data and "next" in data["paging"]:
            url = data["paging"]["next"]
            params = {}
        else:
            break
    
    return total_comments, total_replies

def count_replies_on_comment(comment_id, page_token):
    """R√§kna replies (svar) p√• en specifik kommentar"""
    url = f"https://graph.facebook.com/{API_VERSION}/{comment_id}/comments"
    params = {
        "access_token": page_token,
        "summary": "true",
        "limit": 100
    }
    
    data = api_request(url, params)
    
    if not data:
        return 0
    
    # Anv√§nd summary om tillg√§ngligt
    if "summary" in data and "total_count" in data["summary"]:
        return data["summary"]["total_count"]
    
    # Annars r√§kna manuellt
    if "data" in data:
        return len(data["data"])
    
    return 0

def process_page_for_month(page_id, page_name, year, month):
    """Bearbeta en sida f√∂r en specifik m√•nad och r√§kna kommentarer"""
    logger.info(f"  üìÑ Bearbetar: {page_name}")
    
    # H√§mta Page Access Token
    page_token = get_page_access_token(page_id)
    if not page_token:
        logger.warning(f"    ‚ö†Ô∏è Kunde inte h√§mta Page Access Token, hoppar √∂ver denna sida")
        return {
            "page_id": page_id,
            "page_name": page_name,
            "comments": 0,
            "replies": 0,
            "total": 0
        }
    
    # H√§mta alla posts f√∂r m√•naden
    posts = get_posts_for_month(page_id, page_token, year, month)
    
    if not posts:
        logger.info(f"    ‚ÑπÔ∏è Inga inl√§gg hittades f√∂r {year}-{month:02d}")
        return {
            "page_id": page_id,
            "page_name": page_name,
            "comments": 0,
            "replies": 0,
            "total": 0
        }
    
    logger.info(f"    üìä Hittade {len(posts)} inl√§gg, r√§knar kommentarer...")
    
    total_comments = 0
    total_replies = 0
    
    # R√§kna kommentarer och replies f√∂r varje post
    for i, post in enumerate(posts, 1):
        post_id = post["id"]
        comments, replies = count_comments_on_post(post_id, page_token)
        total_comments += comments
        total_replies += replies
        
        if i % 10 == 0:
            logger.info(f"    ‚è≥ Bearbetat {i}/{len(posts)} inl√§gg...")
    
    total = total_comments + total_replies
    
    logger.info(f"    ‚úÖ Kommentarer: {total_comments}, Replies: {total_replies}, Total: {total}")
    
    return {
        "page_id": page_id,
        "page_name": page_name,
        "comments": total_comments,
        "replies": total_replies,
        "total": total
    }

def save_to_csv(data, year, month):
    """Spara data till CSV-fil"""
    filename = f"FB_Comments_{year}_{month:02d}.csv"
    
    logger.info(f"üíæ Sparar resultat till {filename}...")
    
    try:
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['Page ID', 'Page Name', 'Comments', 'Replies', 'Total']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for row in data:
                writer.writerow({
                    'Page ID': row['page_id'],
                    'Page Name': row['page_name'],
                    'Comments': row['comments'],
                    'Replies': row['replies'],
                    'Total': row['total']
                })
        
        logger.info(f"‚úÖ Sparade {len(data)} sidor till {filename}")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Kunde inte spara CSV: {e}")
        return False

def get_months_to_process(start_year_month, specific_month=None):
    """Best√§m vilka m√•nader som ska bearbetas"""
    if specific_month:
        # Bearbeta endast specifik m√•nad
        try:
            year, month = map(int, specific_month.split('-'))
            return [(year, month)]
        except:
            logger.error(f"‚ùå Ogiltigt m√•nadsformat: {specific_month}. Anv√§nd YYYY-MM")
            return []
    
    # Bearbeta fr√•n startdatum till f√∂reg√•ende m√•nad
    try:
        start_year, start_month = map(int, start_year_month.split('-'))
    except:
        logger.error(f"‚ùå Ogiltigt startdatum: {start_year_month}")
        return []
    
    now = datetime.now()
    current_year = now.year
    current_month = now.month
    
    # F√∂reg√•ende m√•nad
    if current_month == 1:
        end_year = current_year - 1
        end_month = 12
    else:
        end_year = current_year
        end_month = current_month - 1
    
    months = []
    year, month = start_year, start_month
    
    while (year < end_year) or (year == end_year and month <= end_month):
        # Kontrollera om filen redan finns
        filename = f"FB_Comments_{year}_{month:02d}.csv"
        if not os.path.exists(filename):
            months.append((year, month))
        else:
            logger.info(f"‚è≠Ô∏è Hoppar √∂ver {year}-{month:02d} (filen finns redan)")
        
        # N√§sta m√•nad
        if month == 12:
            year += 1
            month = 1
        else:
            month += 1
    
    return months

def main():
    """Huvudfunktion"""
    parser = argparse.ArgumentParser(description='H√§mta kommentarstatistik fr√•n Facebook-sidor')
    parser.add_argument('--month', help='Specifik m√•nad att bearbeta (YYYY-MM)')
    parser.add_argument('--start', help='Startm√•nad (√∂verrider config.py)', default=INITIAL_START_YEAR_MONTH)
    parser.add_argument('--debug', action='store_true', help='Aktivera debug-loggning')
    parser.add_argument('--page-id', help='Specifikt Page ID att bearbeta (annars alla sidor)')
    
    args = parser.parse_args()
    
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    logger.info("=" * 80)
    logger.info("üöÄ FACEBOOK KOMMENTARR√ÑKNARE")
    logger.info("=" * 80)
    
    # Kontrollera token
    if not check_token_expiry():
        logger.error("‚ùå Token-problem. Avbryter.")
        return 1
    
    # H√§mta sidor
    all_pages = get_all_pages()
    if not all_pages:
        logger.error("‚ùå Inga sidor hittades. Avbryter.")
        return 1
    
    # Filtrera placeholder-sidor
    pages = filter_placeholder_pages(all_pages)
    if not pages:
        logger.error("‚ùå Inga giltiga sidor efter filtrering. Avbryter.")
        return 1
    
    # Om inget --page-id argument gavs, fr√•ga anv√§ndaren
    if not args.page_id:
        logger.info("\n" + "=" * 80)
        logger.info("üìã TILLG√ÑNGLIGA SIDOR:")
        logger.info("=" * 80)
        for page_id, page_name in pages[:10]:  # Visa f√∂rsta 10
            logger.info(f"  {page_id} - {page_name}")
        if len(pages) > 10:
            logger.info(f"  ... och {len(pages) - 10} sidor till")
        logger.info("=" * 80)
        
        user_input = input("\nüîç Vilka sidor vill du ha data fr√•n? (alla/PAGE_ID): ").strip()
        
        if user_input.lower() != "alla":
            # Anv√§ndaren valde specifikt Page ID
            selected_page = None
            for page_id, page_name in pages:
                if page_id == user_input:
                    selected_page = (page_id, page_name)
                    break
            
            if not selected_page:
                logger.error(f"‚ùå Page ID '{user_input}' hittades inte i listan. Avbryter.")
                return 1
            
            pages = [selected_page]
            logger.info(f"‚úÖ Valde sida: {selected_page[1]} (ID: {selected_page[0]})")
        else:
            logger.info(f"‚úÖ Bearbetar alla {len(pages)} sidor")
    else:
        # --page-id argument anv√§ndes
        selected_page = None
        for page_id, page_name in pages:
            if page_id == args.page_id:
                selected_page = (page_id, page_name)
                break
        
        if not selected_page:
            logger.error(f"‚ùå Page ID '{args.page_id}' hittades inte. Avbryter.")
            return 1
        
        pages = [selected_page]
        logger.info(f"‚úÖ Bearbetar endast: {selected_page[1]} (ID: {selected_page[0]})")
    
    # Best√§m vilka m√•nader som ska bearbetas
    months_to_process = get_months_to_process(args.start, args.month)
    
    if not months_to_process:
        logger.info("‚úÖ Inga m√•nader att bearbeta.")
        return 0
    
    logger.info(f"üìÖ Kommer att bearbeta {len(months_to_process)} m√•nad(er)")
    
    # Bearbeta varje m√•nad
    for year, month in months_to_process:
        logger.info(f"\n{'='*80}")
        logger.info(f"üìÜ Bearbetar m√•nad: {year}-{month:02d}")
        logger.info(f"{'='*80}")
        
        month_data = []
        
        for page_id, page_name in pages:
            result = process_page_for_month(page_id, page_name, year, month)
            month_data.append(result)
        
        # Spara resultat
        save_to_csv(month_data, year, month)
        
        logger.info(f"\n‚úÖ M√•nad {year}-{month:02d} slutf√∂rd!")
    
    logger.info(f"\n{'='*80}")
    logger.info("üéâ KLART! Alla m√•nader bearbetade.")
    logger.info(f"{'='*80}")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
